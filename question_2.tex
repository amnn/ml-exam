\subsection{Part (a)}

Our model treats each distinct input as an independent Bernoulli random variable, whose probability of success is governed by the input triple that was posed as the question, so we have as many free parameters as the size of our input space. To determine this size we note that, given an input triple $(a : b, c)$:
\begin{itemize}[-]
\itemsep0em
\item All fruit are distinct, that is to say $a\neq b$, $b\neq c$ and $a\neq c$.
\item The choices are ordered: $b\prec c$.
\end{itemize}

There are $n(n-1)(n-2)$ triples of distinct fruit, however, in half of them, the order of the second and third fruit is inverted, so in actuality there are:
\begin{align*}
  \frac{n(n-1)(n-2)}{2}\quad\text{free parameters}
\end{align*}

Because we treat each input independently, we may say that ${y_i\sim\mathbb{1}(p_{b_ic_i}^{a_i})}$. As such, we may give the likelihood as below (taking $\mathbf{p}$ to mean the parameters to our model):

\begin{itemize}
  \step $\operatorname{L}(\langle((a_i : b_i,c_i),y_i)\rangle_{i=1}^m\mid\mathbf{p})$
  \step[=] $\displaystyle\prod\limits_{\substack{i=1\\y_i=1}}^mp_{b_i,c_i}^{a_i}\cdot\prod_{\substack{i=1\\y_i=0}}^m(1 - p_{b_i,c_i}^{a_i})$
\end{itemize}

\subsection{Part (b)}

\begin{itemize}
  \step $\operatorname{NLL}(\langle((a_i:b_i,c_i),y_i)\rangle_{i=1}^m\mid\mathbf{M})$
  \step[=] $-\ln\operatorname{L}(\langle((a_i:b_i,c_i),y_i)\rangle_{i=1}^m\mid\mathbf{M})$
  \step[=] $\displaystyle-\ln\left[\prod_{\substack{i=1\\y_i=1}}^m\frac{e^{M_{a_i,b_i}}}{e^{M_{a_i,b_i}} + e^{M_{a_i,c_i}}}\cdot\prod_{\substack{i=1\\y_i=0}}^m\frac{e^{M_{a_i,c_i}}}{e^{M_{a_i,b_i}}+e^{M_{a_i,c_i}}}\right]$
  \marginnote{Definition of Likelihood (as above)}
  \step[=] $\displaystyle-\sum_{\substack{i=1\\y_i=1}}^m\left[M_{a_i,b_i} - \ln(e^{M_{a_i,b_i}}+e^{M_{a_i,c_i}})\right]$
  \marginnote{Distributing $\ln$ through $\prod$}
  \step $\displaystyle-\sum_{\substack{i=1\\y_i=0}}^m\left[M_{a_i,c_i} - \ln(e^{M_{a_i,b_i}}+e^{M_{a_i,c_i}})\right]$
  \step[=] $\displaystyle\sum_{i=1}^m\ln(e^{M_{a_i,b_i}} + e^{M_{a_i,c_i}}) - \sum_{\substack{i=1\\y_i=1}}^mM_{a_i,b_i} - \sum_{\substack{i=1\\y_i=0}}^mM_{a_i,c_i}$
\end{itemize}

So, when our goal is to find a maximum likelihood estimate, our optimisation problem becomes:
\begin{align*}
  \text{MLE:}\quad\max_{\mathbf{M}}\quad&&
  \sum_{i=1}^m\ln(e^{M_{a_i,b_i}} + e^{M_{a_i,c_i}}) & - \sum_{\substack{i=1\\y_i=1}}^mM_{a_i,b_i} - \sum_{\substack{i=1\\y_i=0}}^mM_{a_i,c_i}\\
  \text{s.t. }\quad&& M_{a,a} & = 1 && \text{for fruit }a
  \\ && M_{a,b} + M_{b,a} & = 1      && \text{for distinct fruits }a,~b
  \\ && 0 \leq M_{a,b} & \leq 1     && \text{for pairs of fruits }a,~b
\end{align*}

\begin{prop}
  MLE is a convex optimisation problem\\[1em]
  \noindent It suffices to show that
  \begin{enumerate}[1.]
    \item All inequality constraints are convex
    \item All equality constraints are linear
    \item The objective function is convex
  \end{enumerate}
\end{prop}

We first make some observations about convex functions, namely that:
\begin{enumerate}[(i)]
  \item Linear functions are convex.
  \item Convex functions are closed under addition.
\end{enumerate}

\begin{proof}[Proof (1/2)]
  By observation (i), as all the constraints are linear, conditions 1 and 2 are met.\qedhere
\end{proof}

\begin{proof}[Proof 3]
  It remains to show that the objective is also convex. First, we split it up as follows:
  \begin{align*}
    \operatorname{MLE}(\mathbf{M}) & =
    \sum_{i=1}^mF_i(\mathbf{M}) - G(\mathbf{M}) - H(\mathbf{M})
    \\\quad\text{where}\quad &
    \\F_i(\mathbf{M}) & = \ln(e^{M_{a_i,b_i}}+e^{M_{a_i,b_i}})
    \\G(\mathbf{M}) & = \sum_{i=1:~y_i=1}^mM_{a_i,b_i}
    \\H(\mathbf{M}) & = \sum_{i=1:~y_i=0}^mM_{a_i,c_i}
  \end{align*}

  $G$ and $H$ are linear, so by observation (i), are convex. Then, by the closure of convexity under addition, it suffices to show that $F_i$ is convex for any $i$. $F_i$ is the projection of $\mathbf{M}$ to $\mathbb{R}^2$ followed by the application of $f(x_1,x_2)=\ln(e^{x_1}+x^{x_2})$, so the convexity of the former follows from that of the latter.

  As $f$ is twice differentiable, we may show that $f$ is convex by verifying that $f$'s Hessian is positive semi-definite.
  \begin{align*}
    \nabla_{\mathbf{x}}f & = \frac{1}{e^{x_1}+e^{x_2}}
    \begin{bmatrix}
      e^{x_1}\\
      e^{x_2}
    \end{bmatrix}
    \\\frac{\partial^2 f}{\partial x_1^2}
    & = \frac{\partial}{\partial x_1}\frac{e^{x_1}}{e^{x_1}+e^{x_2}}
    & = \frac{e^{x_1}(e^{x_1}+e^{x_2}) - e^{2x_1}}{(e^{x_1}+e^{x_2})^2}
    & = \frac{e^{x_1+x_2}}{(e^{x_1}+e^{x_2})^2}
    \\\frac{\partial^2 f}{\partial x_1\partial x_2}
    & = \frac{\partial}{\partial x_1}\frac{e^{x_2}}{e^{x_1}+e^{x_2}}
    && = \frac{-e^{x_1+x_2}}{(e^{x_1}+e^{x_2})^2}
    \intertext{\ldots and symmetrically for \nth{2} differentials in $x_2$}
    \implies\nabla_{\mathbb{x}}^2f & = \frac{e^{x_1+x_2}}{(e^{x_1}+e^{x_2})^2}
    \begin{bmatrix}
      1 & -1\\
      -1 & 1
    \end{bmatrix}
  \end{align*}
  Let $\left[\begin{smallmatrix}a\\b\end{smallmatrix}\right]\in\mathbb{R}^2$
  \begin{align*}
    [\,a,~b\,]
    \nabla_{\mathbf{x}}^2f
    \begin{bmatrix}
      a\\b
    \end{bmatrix}
    & =
    \frac{e^{x_1+x_2}}{(e^{x_1}+e^{x_2})^2}\cdot
      [\,a,~b\,]
    \cdot
    \begin{bmatrix}
      a - b\\
      b - a
    \end{bmatrix}
    \\ & = \frac{e^{x_1+x_2}}{(e^{x_1}+e^{x_2})^2}(a(a-b) + b(b-a))
    \\ & = \frac{e^{x_1+x_2}}{(e^{x_1}+e^{x_2})^2}(a - b)^2
    \\ & \geq 0
    \mathnote{%
      \vspace{-2em}
      \begin{align*}
      (a-b)^2         & \geq 0 \text{ for any } & a, b & \in\mathbb{R} &&&&\\
      \text{and } e^x & \geq 0 \text{ for any } &    x & \in\mathbb{R} &&&&
      \end{align*}
    }
  \end{align*}
  \noindent $\implies \nabla_{\mathbf{x}}^2f$ is positive semi-definite.
  \\\noindent $\implies f$ is convex.\qedhere
\end{proof}

Although we have proven that \textit{MLE} is a convex program, we \textbf{cannot} use \textit{Interior Point Methods}, to find an optimum in polynomial time, as these techniques are only known to work for Linear Programs, Second-Order Cone Programs and Semidefinite Programs\cite{nesterov1994interior}, all of which have linear objective functions (which is not the case for \textit{MLE}). However, convexity does tell us that it suffices for us to search for a local minimum (as that is guaranteed to also be the global minimum, although perhaps not a unique global minimum).\\[1em]

To this end, we might turn to \textit{Higher-Order Newton-Raphson Iteration}, but it is not ideal for a few reasons: Firstly, it converges on stationary points, not optima, and whilst we have shown that the objective is convex, we do not know that it is strictly convex, so it may have saddle points that Newton-Raphson could get stuck in. Another issue is that in order to run Newton-Raphson, at every iteration, we must calculate the gradient and the inverse Hessian for the current parameters. For large numbers of fruit, $n$, this could be a prohibitively expensive operation, as the gradient is a vector in $\mathbb{R}^{n^2}$ and the Hessian is a matrix in $\mathbb{R}^{n^2\times n^2}$.\\[1em]

A more viable approach is to try gradient descent, which is less prone to getting stuck in saddles, especially when techniques such as momentum are used. It is also generally more efficient, per iteration, than Newton-Raphson, as we need only calculate the gradient of the objective with respect to one parameter. \textit{Stochastic Gradient Descent}, and \textit{AdaGrad} are both good examples of this technique.\\[1em]

We may also wish to try \textit{Coordinate descent}, whereby we cycle through the parameters and at each iteration, vary the parameter of interest in order to reduce the objective, (this bears some similarity to SGD). This technique enjoys the same benefits as the aforementioned gradient descent methods, and like them, has been shown to be effective when used to optimise other convex optimisation problems, such as the dual (linear) SVM formulation\cite{hsieh2008dual}.\\[1em]

Any of the last three options would be worth exploring as a means to finding our desired maximum likelihood estimate.

\subsection{Part (c)}

One option is to treat $\mathbf{M}$ as a similarity measure and perform \textit{heirarchical clustering}, measuring the similarity between clusters by the average pairwise similarity of their respective components. This idea of heirarchy may be a useful one as fruit (or the plants they come from) already fall into the taxonomic heirarchy.\\[1em]

As the question tells us that $\mathbf{M}$ is positive semidefinite, we may also embed $\mathbf{M}$ into Euclidean space. Such an embedding allows us to use other techniques, such as \textit{kernel principal component analysis}, \textit{k-means clustering} or \textit{spectral clustering} which may produce clusters with a better fit than heirarchical clustering.\\[1em]

One such embedding can be achieved with \textit{multidimensional scaling}: As we know that $\mathbb{M}$ is positive semidefinite, we know that it arises as the Gram matrix of some $n$ vectors in $\mathbb{R}^f$, let them be the rows of $\mathbf{X}\in\mathbb{R}^{n\times f}$ such that $\mathbf{M} = \mathbf{X}\mathbf{X}^\intercal$.\\[1em]

Given the non-thin Single-Value Decomposition: $\mathbf{X} = \mathbf{U}\boldsymbol\Sigma\mathbf{V}^\intercal$, we can write $\mathbf{M}$ as $\mathbf{U}\boldsymbol\Sigma\boldsymbol\Sigma^\intercal\mathbf{U}^\intercal$. Then we see that $\mathbf{M}$ is the Gram matrix of the rows of $\mathbf{U}\boldsymbol\Sigma = \overset{\sim}{\mathbf{X}}$, which we may use as our embedding.
